{"publication_detail": {"title": "Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better", "authors": ["Dale, David", "Voita, Elena", "Barrault, Lo\u00efc", "Costa-Juss\u00e0, Marta", "Ai, Meta"], "pub_date": ""}, "abstract": "\nWhile the problem of hallucinations in neural machine translation has long been recognized, so far the progress on its alleviation is very little. Indeed, recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative. It means that internal characteristics of the model can give much more information than we expect, and before using external models and measures, we first need to ask: how far can we go if we use nothing but the translation model itself ? We propose to use a method that evaluates the percentage of the source contribution to a generated translation. Intuitively, hallucinations are translations \"detached\" from the source, hence they can be identified by low source contribution. This method improves detection accuracy for the most severe hallucinations by a factor of 2 and is able to alleviate hallucinations at test time on par with the previous best approach that relies on external models. Next, if we move away from internal model characteristics and allow external tools, we show that using sentence similarity from cross-lingual embeddings further improves these results. We release the code of our experiments. 1\n", "citations": [{"citation_text": "artificially perturbing source sentence (Lee et al., 2019;Raunak et al., 2021), adding specific types of noise to the training data (Raunak et al., 2021), working under domain shift (Wang and Sennrich, 2020;M\u00fcller et al., 2020), among others (Zhou et al., 2021). Secondly, hallucinations are hard to identify with automatic metrics.", "publication": {"title": "Hallucinations in neural machine translation", "authors": ["Lee, Katherine", "Firat, Orhan", "Agarwal, Ashish"], "pub_date": "2019"}}, {"citation_text": "artificially perturbing source sentence (Lee et al., 2019;Raunak et al., 2021), adding specific types of noise to the training data (Raunak et al., 2021), working under domain shift (Wang and Sennrich, 2020;M\u00fcller et al., 2020), among others (Zhou et al., 2021). Secondly, hallucinations are hard to identify with automatic metrics.", "publication": {"title": "The curious case of hallucinations in neural machine translation", "authors": ["Vikas Raunak, Arul", "Menezes, Marcin", "Junczys-Dowmunt, "], "pub_date": "2021"}}, {"citation_text": "artificially perturbing source sentence (Lee et al., 2019;Raunak et al., 2021), adding specific types of noise to the training data (Raunak et al., 2021), working under domain shift (Wang and Sennrich, 2020;M\u00fcller et al., 2020), among others (Zhou et al., 2021). Secondly, hallucinations are hard to identify with automatic metrics.", "publication": {"title": "The curious case of hallucinations in neural machine translation", "authors": ["Vikas Raunak, Arul", "Menezes, Marcin", "Junczys-Dowmunt, "], "pub_date": "2021"}}, {"citation_text": "artificially perturbing source sentence (Lee et al., 2019;Raunak et al., 2021), adding specific types of noise to the training data (Raunak et al., 2021), working under domain shift (Wang and Sennrich, 2020;M\u00fcller et al., 2020), among others (Zhou et al., 2021). Secondly, hallucinations are hard to identify with automatic metrics.", "publication": {"title": "Domain robustness in neural machine translation", "authors": ["M\u00fcller, Mathias", "Rios, Annette", "Sennrich, Rico"], "pub_date": "2020"}}, {"citation_text": "artificially perturbing source sentence (Lee et al., 2019;Raunak et al., 2021), adding specific types of noise to the training data (Raunak et al., 2021), working under domain shift (Wang and Sennrich, 2020;M\u00fcller et al., 2020), among others (Zhou et al., 2021). Secondly, hallucinations are hard to identify with automatic metrics.", "publication": {"title": "Detecting hallucinated content in conditional neural sequence generation", "authors": ["Zhou, Chunting", "Neubig, Graham", "Gu, Jiatao", "Diab, Mona", "Guzm\u00e1n, Francisco", "Zettlemoyer, Luke", "Ghazvininejad, Marjan"], "pub_date": "2021"}}, {"citation_text": "Often, hallucinations were defined as translations with low quality according to some metric such as adjusted BLEU or chrF (Lee et al., 2019;Raunak et al., 2021;M\u00fcller and Sennrich, 2021) or translations satisfying some heuristic condition (Berard et al., 2019;Raunak et al., 2021). Overall, it is not clear whether proposed methods detect naturally occurring hallucinations well.", "publication": {"title": "Hallucinations in neural machine translation", "authors": ["Lee, Katherine", "Firat, Orhan", "Agarwal, Ashish"], "pub_date": "2019"}}, {"citation_text": "Often, hallucinations were defined as translations with low quality according to some metric such as adjusted BLEU or chrF (Lee et al., 2019;Raunak et al., 2021;M\u00fcller and Sennrich, 2021) or translations satisfying some heuristic condition (Berard et al., 2019;Raunak et al., 2021). Overall, it is not clear whether proposed methods detect naturally occurring hallucinations well.", "publication": {"title": "The curious case of hallucinations in neural machine translation", "authors": ["Vikas Raunak, Arul", "Menezes, Marcin", "Junczys-Dowmunt, "], "pub_date": "2021"}}, {"citation_text": "Often, hallucinations were defined as translations with low quality according to some metric such as adjusted BLEU or chrF (Lee et al., 2019;Raunak et al., 2021;M\u00fcller and Sennrich, 2021) or translations satisfying some heuristic condition (Berard et al., 2019;Raunak et al., 2021). Overall, it is not clear whether proposed methods detect naturally occurring hallucinations well.", "publication": {"title": "The curious case of hallucinations in neural machine translation", "authors": ["Vikas Raunak, Arul", "Menezes, Marcin", "Junczys-Dowmunt, "], "pub_date": "2021"}}, {"citation_text": "Often, hallucinations were defined as translations with low quality according to some metric such as adjusted BLEU or chrF (Lee et al., 2019;Raunak et al., 2021;M\u00fcller and Sennrich, 2021) or translations satisfying some heuristic condition (Berard et al., 2019;Raunak et al., 2021). Overall, it is not clear whether proposed methods detect naturally occurring hallucinations well.", "publication": {"title": "Naver Labs Europe\u2019s Systems for the WMT19 Machine Translation Robustness Task", "authors": ["Berard, Alexandre", "Calapodescu, Ioan", "Roux, Claude"], "pub_date": "2019"}}, {"citation_text": "Often, hallucinations were defined as translations with low quality according to some metric such as adjusted BLEU or chrF (Lee et al., 2019;Raunak et al., 2021;M\u00fcller and Sennrich, 2021) or translations satisfying some heuristic condition (Berard et al., 2019;Raunak et al., 2021). Overall, it is not clear whether proposed methods detect naturally occurring hallucinations well.", "publication": {"title": "Naver Labs Europe\u2019s Systems for the WMT19 Machine Translation Robustness Task", "authors": ["Berard, Alexandre", "Calapodescu, Ioan", "Roux, Claude"], "pub_date": "2019"}}, {"citation_text": "Recently, when revisiting previous work in a relatively clean setting, Guerreiro et al. (2022) found that existing detection methods fall short and the standard sequence log-probability is the most informative.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "So far, the best realization of this general framework uses sequence log-probability -Seq-Logprob -for detection, Monte Carlo dropout (Gal and Ghahramani, 2016) to generate several alternative translation hypotheses, and COMET-QE to pick the final candidate (see Guerreiro et al. (2022) for the details).", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "Despite the fact that understanding hallucinations was one of the motivations behind the first method evaluating relative source and target contributions, both existing methods only looked at highly artificial hallucinations (Voita et al., 2021;Ferrando et al., 2022). We propose to use ALTI+ by Ferrando et al.", "publication": {"title": "Analyzing the source and target contributions to predictions in neural machine translation", "authors": ["Voita, Elena", "Sennrich, Rico", "Titov, Ivan"], "pub_date": "2021"}}, {"citation_text": "Despite the fact that understanding hallucinations was one of the motivations behind the first method evaluating relative source and target contributions, both existing methods only looked at highly artificial hallucinations (Voita et al., 2021;Ferrando et al., 2022). We propose to use ALTI+ by Ferrando et al.", "publication": {"title": "Towards Opening the Black Box of Neural Machine Translation: Source and Target Interpretations of the Transformer", "authors": ["Ferrando, Javier", "G\u00e1llego, Gerard", "Alastruey, Belen", "Escolano, Carlos", "Costa-Juss\u00e0, Marta"], "pub_date": "-juss\u00e0. 2022"}}, {"citation_text": "We propose to use ALTI+ by Ferrando et al. (2022), the method that aggregates layer-wise tokens attributions, for both hallucination detection and reranking in the \"detect-then-rewrite\" pipeline.", "publication": {"title": "Towards Opening the Black Box of Neural Machine Translation: Source and Target Interpretations of the Transformer", "authors": ["Ferrando, Javier", "G\u00e1llego, Gerard", "Alastruey, Belen", "Escolano, Carlos", "Costa-Juss\u00e0, Marta"], "pub_date": "-juss\u00e0. 2022"}}, {"citation_text": "However, implementing this idea in practice is challenging: even state-of-the-art quality estimation system substantially fails (Guerreiro et al., 2022). We hypothesize that instead of targeting quality evaluation, it might be beneficial to use models trained with a rather different objective.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "However, implementing this idea in practice is challenging: even state-of-the-art quality estimation system substantially fails (Guerreiro et al., 2022). We hypothesize that instead of targeting quality evaluation, it might be beneficial to use models trained with a rather different objective.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "This framework was proposed by Guerreiro et al. (2022) and consists of a large dataset of annotated translations along with the model that produced them.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "The model is Transformer base (Vaswani et al., 2017) from fairseq (Ott et al., 2019) with the standard hyperparameters setting. It was trained on the WMT'18 German-English news translation data excluding Paracrawl (Bojar et al., 2018) -totalling 5.8M sentence pairs.", "publication": {"title": "Attention is all you need", "authors": ["Vaswani, Ashish", "Shazeer, Noam", "Parmar, Niki", "Uszkoreit, Jakob", "Jones, Llion", "Gomez, Aidan", "Kaiser, \u0141 Ukasz", "Polosukhin, Illia"], "pub_date": "2017"}}, {"citation_text": "The model is Transformer base (Vaswani et al., 2017) from fairseq (Ott et al., 2019) with the standard hyperparameters setting. It was trained on the WMT'18 German-English news translation data excluding Paracrawl (Bojar et al., 2018) -totalling 5.8M sentence pairs.", "publication": {"title": "fairseq: A fast, extensible toolkit for sequence modeling", "authors": ["Ott, Myle", "Edunov, Sergey", "Baevski, Alexei", "Fan, Angela", "Gross, Sam", "Ng, Nathan", "Grangier, David", "Auli, Michael"], "pub_date": "2019"}}, {"citation_text": "The model is Transformer base (Vaswani et al., 2017) from fairseq (Ott et al., 2019) with the standard hyperparameters setting. It was trained on the WMT'18 German-English news translation data excluding Paracrawl (Bojar et al., 2018) -totalling 5.8M sentence pairs.", "publication": {"title": "Findings of the 2018 Conference on Machine Translation (WMT18)", "authors": ["Bojar, Ond\u0159ej", "Federmann, Christian", "Fishel, Mark", "Graham, Yvette", "Haddow, Barry", "Koehn, Philipp", "Monz, Christof"], "pub_date": "2018"}}, {"citation_text": "It was trained on the WMT'18 German-English news translation data excluding Paracrawl (Bojar et al., 2018) -totalling 5.8M sentence pairs. Since Guerreiro et al.", "publication": {"title": "Findings of the 2018 Conference on Machine Translation (WMT18)", "authors": ["Bojar, Ond\u0159ej", "Federmann, Christian", "Fishel, Mark", "Graham, Yvette", "Haddow, Barry", "Koehn, Philipp", "Monz, Christof"], "pub_date": "2018"}}, {"citation_text": "Since Guerreiro et al. (2022) used randomly chosen 1/3 of the dataset as a held-out set for analysis, the model was trained on the remaining 2/3 of the dataset.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "We use the model released by Guerreiro et al. (2022) that has been used to generate the hallucinations we analyze.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "The criteria used to flag the translations include 10 methods ranging from previously proposed heuristics (Lee et al., 2019;Berard et al., 2019;Raunak et al., 2021) to quality estimation models (Rei et al., 2020b) and uncertainty detectors (Fomicheva et al., 2020;Zerva et al., 2021;Guerreiro et al., 2022). The taxonomy of translation pathologies in the dataset is shown in Figure 1.", "publication": {"title": "Hallucinations in neural machine translation", "authors": ["Lee, Katherine", "Firat, Orhan", "Agarwal, Ashish"], "pub_date": "2019"}}, {"citation_text": "The criteria used to flag the translations include 10 methods ranging from previously proposed heuristics (Lee et al., 2019;Berard et al., 2019;Raunak et al., 2021) to quality estimation models (Rei et al., 2020b) and uncertainty detectors (Fomicheva et al., 2020;Zerva et al., 2021;Guerreiro et al., 2022). The taxonomy of translation pathologies in the dataset is shown in Figure 1.", "publication": {"title": "The curious case of hallucinations in neural machine translation", "authors": ["Vikas Raunak, Arul", "Menezes, Marcin", "Junczys-Dowmunt, "], "pub_date": "2021"}}, {"citation_text": "The criteria used to flag the translations include 10 methods ranging from previously proposed heuristics (Lee et al., 2019;Berard et al., 2019;Raunak et al., 2021) to quality estimation models (Rei et al., 2020b) and uncertainty detectors (Fomicheva et al., 2020;Zerva et al., 2021;Guerreiro et al., 2022). The taxonomy of translation pathologies in the dataset is shown in Figure 1.", "publication": {"title": "Naver Labs Europe\u2019s Systems for the WMT19 Machine Translation Robustness Task", "authors": ["Berard, Alexandre", "Calapodescu, Ioan", "Roux, Claude"], "pub_date": "2019"}}, {"citation_text": "The criteria used to flag the translations include 10 methods ranging from previously proposed heuristics (Lee et al., 2019;Berard et al., 2019;Raunak et al., 2021) to quality estimation models (Rei et al., 2020b) and uncertainty detectors (Fomicheva et al., 2020;Zerva et al., 2021;Guerreiro et al., 2022). The taxonomy of translation pathologies in the dataset is shown in Figure 1.", "publication": {"title": "Multi-hypothesis machine translation evaluation", "authors": ["Fomicheva, Marina", "Specia, Lucia", "Guzm\u00e1n, Francisco"], "pub_date": "2020"}}, {"citation_text": "The criteria used to flag the translations include 10 methods ranging from previously proposed heuristics (Lee et al., 2019;Berard et al., 2019;Raunak et al., 2021) to quality estimation models (Rei et al., 2020b) and uncertainty detectors (Fomicheva et al., 2020;Zerva et al., 2021;Guerreiro et al., 2022). The taxonomy of translation pathologies in the dataset is shown in Figure 1.", "publication": {"title": "IST-unbabel 2021 submission for the quality estimation shared task", "authors": ["Zerva, Chrysoula", "Van Stigt, Daan", "Rei, Ricardo", "Farinha, Ana", "Ramos, Pedro", "Jos\u00e9, G", "De Souza, Taisiya", "Glushkova, Miguel", "Vera, Fabio", "Kepler, ", "Andr\u00e9, F", "Martins, "], "pub_date": "2021"}}, {"citation_text": "The criteria used to flag the translations include 10 methods ranging from previously proposed heuristics (Lee et al., 2019;Berard et al., 2019;Raunak et al., 2021) to quality estimation models (Rei et al., 2020b) and uncertainty detectors (Fomicheva et al., 2020;Zerva et al., 2021;Guerreiro et al., 2022). The taxonomy of translation pathologies in the dataset is shown in Figure 1.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "Note that so far, there is no \"canonical\" hallucination taxonomy and previous work used various, mostly overlapping, definitions (Lee et al., 2019;Raunak et al., 2021;Zhou et al., 2021;Ji et al., 2022;Raunak et al., 2022;Guerreiro et al., 2022). We follow the taxonomy by Guerreiro et al.", "publication": {"title": "Hallucinations in neural machine translation", "authors": ["Lee, Katherine", "Firat, Orhan", "Agarwal, Ashish"], "pub_date": "2019"}}, {"citation_text": "Note that so far, there is no \"canonical\" hallucination taxonomy and previous work used various, mostly overlapping, definitions (Lee et al., 2019;Raunak et al., 2021;Zhou et al., 2021;Ji et al., 2022;Raunak et al., 2022;Guerreiro et al., 2022). We follow the taxonomy by Guerreiro et al.", "publication": {"title": "The curious case of hallucinations in neural machine translation", "authors": ["Vikas Raunak, Arul", "Menezes, Marcin", "Junczys-Dowmunt, "], "pub_date": "2021"}}, {"citation_text": "Note that so far, there is no \"canonical\" hallucination taxonomy and previous work used various, mostly overlapping, definitions (Lee et al., 2019;Raunak et al., 2021;Zhou et al., 2021;Ji et al., 2022;Raunak et al., 2022;Guerreiro et al., 2022). We follow the taxonomy by Guerreiro et al.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "Note that so far, there is no \"canonical\" hallucination taxonomy and previous work used various, mostly overlapping, definitions (Lee et al., 2019;Raunak et al., 2021;Zhou et al., 2021;Ji et al., 2022;Raunak et al., 2022;Guerreiro et al., 2022). We follow the taxonomy by Guerreiro et al.", "publication": {"title": "Detecting hallucinated content in conditional neural sequence generation", "authors": ["Zhou, Chunting", "Neubig, Graham", "Gu, Jiatao", "Diab, Mona", "Guzm\u00e1n, Francisco", "Zettlemoyer, Luke", "Ghazvininejad, Marjan"], "pub_date": "2021"}}, {"citation_text": "Note that so far, there is no \"canonical\" hallucination taxonomy and previous work used various, mostly overlapping, definitions (Lee et al., 2019;Raunak et al., 2021;Zhou et al., 2021;Ji et al., 2022;Raunak et al., 2022;Guerreiro et al., 2022). We follow the taxonomy by Guerreiro et al.", "publication": {"title": "Survey of hallucination in natural language generation", "authors": ["Ji, Ziwei", "Lee, Nayeon", "Frieske, Rita", "Yu, Tiezheng", "Su, Dan", "Xu, Yan", "Ishii, Etsuko", "Bang, Yejin", "Madotto, Andrea", "Fung, Pascale"], "pub_date": "2022"}}, {"citation_text": "Note that so far, there is no \"canonical\" hallucination taxonomy and previous work used various, mostly overlapping, definitions (Lee et al., 2019;Raunak et al., 2021;Zhou et al., 2021;Ji et al., 2022;Raunak et al., 2022;Guerreiro et al., 2022). We follow the taxonomy by Guerreiro et al.", "publication": {"title": "Salted: A framework for salient long-tail translation error detection", "authors": ["Raunak, Vikas", "Post, Matt", "Menezes, Arul"], "pub_date": "2022"}}, {"citation_text": "We follow the taxonomy by Guerreiro et al. (2022) for consistency with the dataset and the evaluation framework we use and because this taxonomy is general enough for our purposes.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "Following previous work (M\u00fcller and Sennrich, 2021;Guerreiro et al., 2022), we use: \u2022 chrF: character n-gram F score of the translation with respect to the reference. We use the CHRF++ version that also takes into account word unigrams and bigrams (Popovi\u0107, 2017); \u2022 COMET: a neural quality estimation metric by Rei et al.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "Compared to previously introduced methods specifically targeting hallucinations, this simple metric performs the best (Guerreiro et al., 2022). We use ALTI: percentage of source contribution.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "Compared to previously introduced methods specifically targeting hallucinations, this simple metric performs the best (Guerreiro et al., 2022). We use ALTI: percentage of source contribution.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "We compute the percentage of source impact on the generated translation using the recently introduced ALTI+ (Ferrando et al., 2022). At a high level, it decomposes each transformer block into a sum of functions of individual tokens and views an output representation as a summation of transformed input vectors.", "publication": {"title": "Towards Opening the Black Box of Neural Machine Translation: Source and Target Interpretations of the Transformer", "authors": ["Ferrando, Javier", "G\u00e1llego, Gerard", "Alastruey, Belen", "Escolano, Carlos", "Costa-Juss\u00e0, Marta"], "pub_date": "-juss\u00e0. 2022"}}, {"citation_text": "We compute the percentage of source impact on the generated translation using the recently introduced ALTI+ (Ferrando et al., 2022). At a high level, it decomposes each transformer block into a sum of functions of individual tokens and views an output representation as a summation of transformed input vectors.", "publication": {"title": "Towards Opening the Black Box of Neural Machine Translation: Source and Target Interpretations of the Transformer", "authors": ["Ferrando, Javier", "G\u00e1llego, Gerard", "Alastruey, Belen", "Escolano, Carlos", "Costa-Juss\u00e0, Marta"], "pub_date": "-juss\u00e0. 2022"}}, {"citation_text": "Among other things, ALTI+ (as well as an earlier Layerwise Relevance Propagation (LRP) -based method by Voita et al. (2021)) was used to show that for artificially created hallucinations, source influence is much lower than for \"healthy\" translations.", "publication": {"title": "Analyzing the source and target contributions to predictions in neural machine translation", "authors": ["Voita, Elena", "Sennrich, Rico", "Titov, Ivan"], "pub_date": "2021"}}, {"citation_text": "For a reference-free model, we use the state-of-the-art COMET-QE (Rei et al., 2020b) for its superior performance compared to other quality estimators (Mathur et al., 2020;Freitag et al., 2021;Kocmi et al., 2021). We use: sentence similarity.", "publication": {"title": "Results of the WMT20 metrics shared task", "authors": ["Mathur, Nitika", "Wei, Johnny", "Freitag, Markus", "Ma, Qingsong", "Bojar, Ond\u0159ej"], "pub_date": "2020"}}, {"citation_text": "LASER2 (Heffernan et al., 2022) improves LASER (Artetxe and Schwenk, 2019) by replacing LSTM encoder with a Transformer and using teacher-student training; \u2022 LaBSE: cosine similarity of source and translation sentence embeddings from LaBSE (Feng et al., 2022). LaBSE is a dual-encoder approach based on pretrained transformers and fine-tuned for translation ranking with an additive margin softmax loss; \u2022 XNLI: product of the entailment probabilities of source to translation and translation to source.", "publication": {"title": "Bitext mining using distilled sentence representations for low-resource languages", "authors": ["Heffernan, Kevin", "\u00c7elebi, Onur", "Schwenk, Holger"], "pub_date": "2022"}}, {"citation_text": "LASER2 (Heffernan et al., 2022) improves LASER (Artetxe and Schwenk, 2019) by replacing LSTM encoder with a Transformer and using teacher-student training; \u2022 LaBSE: cosine similarity of source and translation sentence embeddings from LaBSE (Feng et al., 2022). LaBSE is a dual-encoder approach based on pretrained transformers and fine-tuned for translation ranking with an additive margin softmax loss; \u2022 XNLI: product of the entailment probabilities of source to translation and translation to source.", "publication": {"title": "Language-agnostic BERT Sentence Embedding", "authors": ["Feng, Fangxiaoyu", "Yang, Yinfei", "Cer, Daniel", "Arivazhagan, Naveen", "Wang, Wei"], "pub_date": "2022"}}, {"citation_text": "We compute entailment scores with RoBERTa (Conneau et al., 2020) finetuned on a combination of NLI data in 15 languages (Conneau et al., 2018). 4   4 Detection Experiments Overall results are shown in Table 1.", "publication": {"title": "Unsupervised Cross-lingual Representation Learning at Scale", "authors": ["Conneau, Alexis", "Khandelwal, Kartikay", "Goyal, Naman", "Chaudhary, Vishrav", "Wenzek, Guillaume", "Guzm\u00e1n, Francisco", "Grave, Edouard", "Ott, Myle", "Zettlemoyer, Luke", "Stoyanov, Veselin"], "pub_date": "2020"}}, {"citation_text": "This agrees with previous work noting that since quality estimation models are mostly trained on data that lacks negative examples, COMETs may be inadequate at evaluating poor translations in general (Takahashi et al., 2021;Sudoh et al., 2021) and hallucinations in particular (Guerreiro et al., 2022). What is also expected, is that compared to reference-free COMET-QE, the overlap between the scores for correct and incorrect translations is much lower for reference-based COMET.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "This agrees with previous work noting that since quality estimation models are mostly trained on data that lacks negative examples, COMETs may be inadequate at evaluating poor translations in general (Takahashi et al., 2021;Sudoh et al., 2021) and hallucinations in particular (Guerreiro et al., 2022). What is also expected, is that compared to reference-free COMET-QE, the overlap between the scores for correct and incorrect translations is much lower for reference-based COMET.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "This agrees with previous work noting that since quality estimation models are mostly trained on data that lacks negative examples, COMETs may be inadequate at evaluating poor translations in general (Takahashi et al., 2021;Sudoh et al., 2021) and hallucinations in particular (Guerreiro et al., 2022). What is also expected, is that compared to reference-free COMET-QE, the overlap between the scores for correct and incorrect translations is much lower for reference-based COMET.", "publication": {"title": "Multilingual machine translation evaluation metrics fine-tuned on pseudonegative examples for wmt 2021 metrics task", "authors": ["Takahashi, Kosuke", "Ishibashi, Yoichi", "Sudoh, Katsuhito", "Nakamura, Satoshi"], "pub_date": "2021"}}, {"citation_text": "This agrees with previous work noting that since quality estimation models are mostly trained on data that lacks negative examples, COMETs may be inadequate at evaluating poor translations in general (Takahashi et al., 2021;Sudoh et al., 2021) and hallucinations in particular (Guerreiro et al., 2022). What is also expected, is that compared to reference-free COMET-QE, the overlap between the scores for correct and incorrect translations is much lower for reference-based COMET.", "publication": {"title": "Is this translation error critical?: Classification-based human and automatic machine translation evaluation focusing on critical errors", "authors": ["Sudoh, Katsuhito", "Takahashi, Kosuke", "Nakamura, Satoshi"], "pub_date": "2021"}}, {"citation_text": "Finally, let us come to the second part of the \"detectthen-rewrite\" pipeline: for a flagged translation, generate several alternative hypotheses and rerank them (Guerreiro et al., 2022) 8 . This general framework has two degrees of freedom: (i) generation of hypotheses, (ii) reranking approach.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "Finally, let us come to the second part of the \"detectthen-rewrite\" pipeline: for a flagged translation, generate several alternative hypotheses and rerank them (Guerreiro et al., 2022) 8 . This general framework has two degrees of freedom: (i) generation of hypotheses, (ii) reranking approach.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "nucleus sampling (Holtzman et al., 2020); \u2022 diverse beam search: \u2022 DBS_N: method by Vijayakumar et al. (2016) with beam widths s = 1, 3, 10; \u2022 D_DEC_R: diverse decoding with diversity rates r = 1, 3, 10 (Li et al., 2016); \u2022 Monte Carlo dropout: \u2022 MC GREEDY: n iterations of greedy search with dropout; \u2022 MC BEAM: the method used in Guerreiro et al.", "publication": {"title": "The curious case of neural text degeneration", "authors": ["Holtzman, Ari", "Buys, Jan", "Du, Li", "Forbes, Maxwell", "Choi, Yejin"], "pub_date": "2020"}}, {"citation_text": "As rerankers, we considered COMET-QE used in Guerreiro et al. (2022) and the methods proposed in Section 3.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "Next, differently from modifying decoding strategies, here variability in hypotheses comes from model predictive uncertainty (Gal and Ghahramani, 2016;Zerva et al., 2021;Guerreiro et al., 2022). This is one more evidence that understanding model inner characteristics can be beneficial in various settings.", "publication": {"title": "IST-unbabel 2021 submission for the quality estimation shared task", "authors": ["Zerva, Chrysoula", "Van Stigt, Daan", "Rei, Ricardo", "Farinha, Ana", "Ramos, Pedro", "Jos\u00e9, G", "De Souza, Taisiya", "Glushkova, Miguel", "Vera, Fabio", "Kepler, ", "Andr\u00e9, F", "Martins, "], "pub_date": "2021"}}, {"citation_text": "Next, differently from modifying decoding strategies, here variability in hypotheses comes from model predictive uncertainty (Gal and Ghahramani, 2016;Zerva et al., 2021;Guerreiro et al., 2022). This is one more evidence that understanding model inner characteristics can be beneficial in various settings.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "Therefore, COMETs may be inadequate at evaluating poor translations in general and hallucinations in particular (Takahashi et al., 2021;Sudoh et al., 2021;Guerreiro et al., 2022). For reranking, the goal is the opposite: finding the best translations (as opposed to the worst), which is closer to the COMET training objective.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "Therefore, COMETs may be inadequate at evaluating poor translations in general and hallucinations in particular (Takahashi et al., 2021;Sudoh et al., 2021;Guerreiro et al., 2022). For reranking, the goal is the opposite: finding the best translations (as opposed to the worst), which is closer to the COMET training objective.", "publication": {"title": "Multilingual machine translation evaluation metrics fine-tuned on pseudonegative examples for wmt 2021 metrics task", "authors": ["Takahashi, Kosuke", "Ishibashi, Yoichi", "Sudoh, Katsuhito", "Nakamura, Satoshi"], "pub_date": "2021"}}, {"citation_text": "Therefore, COMETs may be inadequate at evaluating poor translations in general and hallucinations in particular (Takahashi et al., 2021;Sudoh et al., 2021;Guerreiro et al., 2022). For reranking, the goal is the opposite: finding the best translations (as opposed to the worst), which is closer to the COMET training objective.", "publication": {"title": "Is this translation error critical?: Classification-based human and automatic machine translation evaluation focusing on critical errors", "authors": ["Sudoh, Katsuhito", "Takahashi, Kosuke", "Nakamura, Satoshi"], "pub_date": "2021"}}, {"citation_text": "This work is based on the open source dataset and model released by Guerreiro et al. (2022) and thus inherits all their potential biases.", "publication": {"title": "Looking for a needle in a haystack: A comprehensive study of hallucinations in neural machine translation", "authors": ["Nuno, M", "Guerreiro, Elena", "Voita, ", "Andr\u00e9, F"], "pub_date": "Martins. 2022"}}, {"citation_text": "To compute ALTI+, we adapt the code 13 by Ferrando et al. (2022).", "publication": {"title": "Towards Opening the Black Box of Neural Machine Translation: Source and Target Interpretations of the Transformer", "authors": ["Ferrando, Javier", "G\u00e1llego, Gerard", "Alastruey, Belen", "Escolano, Carlos", "Costa-Juss\u00e0, Marta"], "pub_date": "-juss\u00e0. 2022"}}, {"citation_text": "To compute ALTI+, we adapt the code 13 by Ferrando et al. (2022).", "publication": {"title": "Towards Opening the Black Box of Neural Machine Translation: Source and Target Interpretations of the Transformer", "authors": ["Ferrando, Javier", "G\u00e1llego, Gerard", "Alastruey, Belen", "Escolano, Carlos", "Costa-Juss\u00e0, Marta"], "pub_date": "-juss\u00e0. 2022"}}]}